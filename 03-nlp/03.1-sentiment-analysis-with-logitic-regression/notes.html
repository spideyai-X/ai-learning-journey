<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sentiment Analysis with Logistic Regression Notes</title>

    <link rel="stylesheet" href="../../styles/main.css">
    <style>
        .container img { display:block; margin: 16px auto; max-width: 65%; height: auto; }
    </style>
    
    <link rel="stylesheet" href="../../styles/katex.min.css">
    <script defer src="../../styles/katex.min.js"></script>
    <script defer src="../../styles/auto-render.min.js"></script>

    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '\\[', right: '\\]', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false}
                ]
            });
        });
    </script>
</head>
<body>
    <div class="container">
        <p>My goal in this section is to build a sentiment analysis model using Logistic Regression. This model will classify tweets as either positive or negative.</p>

        <img src="./images/sentiment-analysis-class.png" alt="Sentiment Analysis Class">

        <h1>1. The Supervised Learning Framework</h1>
        <p>The core idea is to train a model using labeled data. In our case, the features $X$ are the tweets, and the labels $Y$ are their sentiments (1 for positive, 0 for negative).</p>
        <p>The training process is an iterative loop:</p>
        <ol>
            <li>Input features $X$ into a prediction function.</li>
            <li>The function, using its current parameters $\theta$, generates a prediction $\hat{Y}$.</li>
            <li>We calculate the <strong>Cost</strong>, which measures how far $\hat{Y}$ is from the actual label $Y$.</li>
            <li>We adjust the parameters $\theta$ (using an optimizer like Gradient Descent) to minimize this cost.</li>
        </ol>
        <img src="./images/supervised-ml-training.png" alt="Supervised ML Training">

        <h1>2. Feature Extraction: From Text to Numbers</h1>
        <p>A model can't understand raw text. We need to convert each tweet into a numerical vector.</p>
        <img src="./images/vector-representation.png" alt="Vector Representation">

        <h3>2.1. Method 1: Sparse Representation (Bag of Words)</h3>
        <p>The most straightforward way is to create a feature vector for each tweet based on a vocabulary $V$ (the set of all unique words across all tweets, our corpus).</p>
        <p>For a single tweet, the feature vector $x$ would have the size of $V$. Each element of $x$ is 1 if the corresponding word from $V$ is in the tweet, and 0 otherwise. This can be expressed as:</p>
        $$x_i = \begin{cases} 1 & \text{if word } i \in \text{tweet} \\ 0 & \text{otherwise} \end{cases}$$
        <img src="./images/feature-extraction.png" alt="Feature extraction">
        <p>This is called a <strong>sparse representation</strong> because for a large vocabulary, the vector will be mostly zeros.</p>
        <p><strong>Problem</strong>: If $V$ contains 10,000 words, our model needs to train on 10,001 parameters ($n+1$, where $n$ is the size of $V$ and $+1$ is for the bias term). This can be computationally very expensive.</p>
        <img src="./images/problem-with-sparse-representation.png" alt="Problem with sparse representation">

        <h3>2.2. Method 2: Feature Engineering with Word Frequencies</h3>
        <p>To avoid large vectors, we can engineer more meaningful features. Instead of a huge sparse vector, we can represent each tweet with a dense vector of only 3 features.</p>
        <p>First, we pre-calculate a frequency map (<code>freqs</code>) for every word in our vocabulary $V$. This map stores how many times each word appears in positive tweets versus negative tweets.</p>
        <img src="./images/word-frequency.png" alt="Word frequency">
        <p>Now, for any given tweet $m$, we can build its feature vector $x_m$ as follows:</p>
        <ol>
            <li><strong>Feature 1 (Bias Unit)</strong>: Always <code>1</code>.</li>
            <li><strong>Feature 2 (Positive Score)</strong>: The sum of the positive frequencies for every unique word in the tweet.</li>
            <li><strong>Feature 3 (Negative Score)</strong>: The sum of the negative frequencies for every unique word in the tweet.</li>
        </ol>
        <img src="./images/pos-freq-sum.png" alt="Positive Frequency Sum">
        <img src="./images/feature-extraction-calculus.png" alt="Calculus">
        <p>This transforms a long, sparse vector into a very small, dense vector like <code>[1, 8, 11]</code>, which is much more efficient for training.</p>
        <img src="./images/features-3d-vector.png" alt="Features 3D vector">

        <h1>3. Text Preprocessing</h1>
        <p>To get meaningful features, we must clean the raw text first. The goal is to reduce noise and standardize the words.</p>
        <ol>
            <li><strong>Remove Noise</strong>: Get rid of elements that don't carry sentiment, like Twitter handles (<code>@user</code>), URLs, and retweet markers (<code>RT</code>).</li>
            <img src="./images/handles-and-urls-removing.png" alt="Handles and URLs Removing">
            <li><strong>Tokenize</strong>: Split the text into a list of individual words (tokens).</li>
            <li><strong>Remove Stop Words and Punctuation</strong>: Filter out common words (<code>a</code>, <code>the</code>, <code>is</code>) and punctuation that don't add meaning. <em>Note: This step is context-dependent. For sentiment analysis, emoticons like <code>:)</code> are valuable and should be kept.</em></li>
            <img src="./images/stop-words-removing.png" alt="Stop Words Removing">
            <li><strong>Stemming</strong>: Reduce words to their root form (e.g., <code>learning</code>, <code>learned</code> -> <code>learn</code>). This helps group related words, reducing the vocabulary size.</li>
            <img src="./images/stemming.png" alt="Stemming">
            <li><strong>Lowercasing</strong>: Convert all text to lowercase to treat words like <code>Great</code> and <code>great</code> as the same token.</li>
            <img src="./images/lowercasing.png" alt="Lowercasing">
        </ol>
        <p>After these steps, a raw tweet is transformed into a clean list of tokens, ready for feature extraction.</p>
        <img src="./images/original-tweet.png" alt="Original tweet">
        <img src="./images/preprocessed-tweet.png" alt="Preprocessed tweet">

        <h1>4. Building the Feature Matrix</h1>
        <p>The final step is to apply this process to our entire corpus of tweets. Each tweet is converted into its 3-feature vector. These vectors are then stacked together to form a single matrix <code>X</code>.</p>
        <p>Each row in the matrix <code>X</code> represents a tweet, and each column represents a feature. This matrix, along with the corresponding label vector <code>Y</code>, is what we'll use to train our logistic regression model.</p>
        <img src="./images/multiple-datas-matrix.png" alt="Multiple datas matrix">
        <img src="./images/multiple-datas-way.png" alt="Multiple datas way">

        <h1>5. Logistic Regression for Classification</h1>
        <p>After extracting features, the next step is to build a model that can classify a tweet as positive or negative. For this, we use Logistic Regression, a classification algorithm that predicts a probability.</p>

        <h3>5.1. The Hypothesis Function</h3>
        <p>The core of logistic regression is the <strong>hypothesis function</strong>, denoted as $h(x)$, which estimates the probability that the output is 1. In our case, it's the probability of a tweet being positive.</p>
        <p>The hypothesis is defined using the <strong>sigmoid function</strong>, $g(z)$:</p>
        $$ h(x) = g(\theta^T x) $$
        <p>Where:</p>
        <ul>
            <li>$\theta$ is the vector of model parameters (weights).</li>
            <li>$x$ is the feature vector.</li>
            <li>$\theta^T x$ is the dot product of the parameters and features.</li>
        </ul>
        <p>The sigmoid function is defined as:</p>
        $$ g(z) = \frac{1}{1 + e^{-z}} $$
        <p>This function always outputs a value between 0 and 1, which is perfect for representing a probability.</p>
        <img src="./images/sigmoid-function-maths.png" alt="Sigmoid function maths">
        <img src="./images/sigmoid-function-plot.png" alt="Sigmoid function plot">
        <img src="./images/sigmoid-probability.png" alt="Sigmoid probability">

        <h3>5.2. The Decision Boundary</h3>
        <p>To make a final classification (0 or 1), we need a threshold. By convention, we use 0.5:</p>
        <ul>
            <li>If $h(x) \ge 0.5$, we predict <strong>positive sentiment</strong> (Y=1).</li>
            <li>If $h(x) < 0.5$, we predict <strong>negative sentiment</strong> (Y=0).</li>
        </ul>
        <p>Looking at the sigmoid plot, $g(z) \ge 0.5$ when its input $z \ge 0$. Since our input is $z = \theta^T x$, this means:</p>
        $$ \theta^T x \ge 0 \implies \text{Predict Positive} $$
        $$ \theta^T x < 0 \implies \text{Predict Negative} $$
        <p>The line defined by $\theta^T x = 0$ is called the <strong>decision boundary</strong>. It's the line that separates the two predicted classes.</p>

        <h3>5.3. Training the Model</h3>
        <p>The goal of training is to find the optimal parameters $\theta$ that minimize the difference between our predictions ($\hat{Y}$) and the actual labels ($Y$). This is achieved by minimizing a <strong>cost function</strong> using an optimization algorithm like Gradient Descent.</p>
        <img src="./images/logistic-regression-overview.png" alt="Overview of Logistic Regression">

        <h3>5.4. Example Walkthrough</h3>
        <p>Let's assume we have already trained our model and found the optimal parameters $\theta$. Now, we can predict the sentiment of a new tweet.</p>
        <ol>
            <li><strong>Preprocessing</strong>: The raw tweet is cleaned (lowercased, tokenized, stopwords removed, stemmed).</li>
            <li><strong>Feature Extraction</strong>: We create the feature vector $x$ using the word frequency method.</li>
            <li><strong>Prediction</strong>: We compute the dot product $\theta^T x$ and apply the sigmoid function to get the probability.</li>
        </ol>
        <img src="./images/process-to-sentiment.png" alt="Process to sentiment">
        <p>In this example, the dot product $\theta^T x$ is 4.92.</p>
        $$ h(x) = g(4.92) = \frac{1}{1 + e^{-4.92}} \approx 0.993 $$
        <p>Since $0.993 \ge 0.5$, the model correctly predicts a <strong>positive sentiment</strong>.</p>

        <h3>5.5. Logistic Regression Training: Gradient Descent</h3>
        <p>To train a logistic regression classifier, we need to find the optimal parameters, $\theta$, that minimize the <strong>cost function</strong>, $J(\theta)$. This iterative process is carried out using the <strong>Gradient Descent</strong> algorithm.</p>
        <img src="./images/cost-function-iterations.png" alt="Cost function iterations">
        <p>Here's how the process works:</p>
        <ol>
            <li><strong>Initialize Parameters</strong>: Start by initializing the parameters $\theta$ with arbitrary values, typically zeros.</li>
            <li><strong>Calculate Prediction</strong>: For each observation, compute the prediction, $h_\theta(x^{(i)})$, using the sigmoid function and the current parameters.</li>
            <li><strong>Calculate the Gradient</strong>: Compute the gradient of the cost function with respect to each parameter $\theta_j$. The gradient indicates the direction and magnitude of the steepest ascent of the cost function. Our goal is to move in the opposite direction.</li>
            <li><strong>Update Parameters</strong>: Update the parameters by subtracting a fraction of the gradient. The learning rate, $\alpha$, controls the size of each step.
                <p>$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)$</p>
            </li>
            <li><strong>Iterate</strong>: Repeat steps 2 through 4 until convergence is reached. This occurs when the cost function no longer decreases significantly. At this point, we have found the parameters that minimize the cost function, allowing for the most accurate predictions possible.</li>
        </ol>
        <img src="./images/gradient-descent.png" alt="Gradient descent">

        <h1>6. Evaluating the Model</h1>
        <p>Once the model is trained, we need to evaluate its performance on data it has never seen before. This process tells us how well our model <strong>generalizes</strong> to new, real-world examples. For this, we use a <strong>validation set</strong> (or test set) composed of a feature matrix $X_{val}$ and a label vector $Y_{val}$.</p>

        <h3>6.1. Generating Predictions on the Validation Set</h3>
        <p>The first step is to use our trained parameters $\theta$ to make predictions on the validation data.</p>
        <ol>
            <li><strong>Compute Probabilities</strong>: We feed the validation feature matrix $X_{val}$ into our hypothesis function. This computes the predicted probability for each tweet in the validation set.
                $$\hat{P}_{val} = g(X_{val} \theta)$$
                The result, $\hat{P}_{val}$, is a vector of probabilities, where each element is between 0 and 1.
                <br>
                <img src="./images/model-prediction-vector.png" alt="Model prediction vector">
            </li>
            <li><strong>Apply the Decision Boundary</strong>: To get a final class label (0 or 1), we apply our 0.5 threshold to the probability vector.
                $$y_{pred} = (\hat{P}_{val} \ge 0.5)$$
                This operation creates a new vector, <code>y_pred</code>, populated with 0s and 1s, representing the model's final prediction for each tweet (0 for negative, 1 for positive).
                <br>
                <img src="./images/model-prediction-compute.png" alt="Model prediction compute">
            </li>
        </ol>

        <h3>6.2. Measuring Performance with Accuracy</h3>
        <p>Now that we have a prediction vector <code>y_pred</code>, we can compare it to the true labels in $Y_{val}$ to calculate the model's accuracy.</p>
        <p><strong>Accuracy</strong> is the proportion of predictions that the model got correct.</p>
        <ol>
            <li><strong>Compare Predictions to True Labels</strong>: We perform an element-wise comparison between our prediction vector <code>y_pred</code> and the true label vector $Y_{val}$. This results in a vector of booleans (True/False) or integers (1/0), where a <code>1</code> indicates a correct prediction and a <code>0</code> indicates an error.
                <br>
                <img src="./images/model-accuracy-compute.png" alt="Model accuracy compute">
                <p>For example, if <code>y_pred = [0, 1, 1]</code> and <code>Y_val = [0, 0, 1]</code>, the comparison yields <code>[1, 0, 1]</code>.</p>
                <img src="./images/model-accuracy-compute-compare.png" alt="Model accuracy vector">
            </li>
            <li><strong>Calculate the Accuracy Score</strong>: The accuracy is the sum of the correct predictions divided by the total number of examples.
                $$\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}} = \frac{\sum_{i=1}^{m} (y_{pred}^{(i)} == y_{val}^{(i)})}{m}$$
                Where $m$ is the number of examples in the validation set.
                <p>For example, if we had 4 correct predictions out of 5 total tweets, the accuracy would be:</p>
                $$\text{Accuracy} = \frac{4}{5} = 0.8$$
                <p>This means the model has an <strong>80% accuracy</strong> on the validation set.</p>
            </li>
        </ol>

        <h3>6.3. A Note on Data Splitting</h3>
        <p>To ensure an unbiased evaluation, the dataset is typically split into three parts before training begins:</p>
        <ul>
            <li><strong>Training Set</strong>: The largest portion of the data (e.g., 80%), used to train the model and find the optimal parameters $\theta$.</li>
            <li><strong>Validation Set</strong>: A smaller portion (e.g., 10%), used to evaluate the model during development and tune hyperparameters (like the learning rate). The accuracy we calculated above is on this set.</li>
            <li><strong>Test Set</strong>: A final, held-out portion (e.g., 10%) that the model never sees during training or tuning. This set is used only once at the very end to provide a final, unbiased measure of the model's real-world performance.</li>
        </ul>
        <p>A common split is 80% for training, 10% for validation, and 10% for testing.</p>

        <h1>7. Pros and Cons of Logistic Regression</h1>
        <h3>Pros:</h3>
        <ul>
            <li><strong>Interpretable</strong>: The model provides clear probabilities and the coefficients can be interpreted as feature importance.</li>
            <li><strong>Efficient</strong>: Training and prediction are computationally fast, especially with our 3-feature representation.</li>
            <li><strong>No Assumptions</strong>: Unlike Naive Bayes, it doesn't assume conditional independence between features.</li>
            <li><strong>Probabilistic Output</strong>: Provides probability scores, not just binary predictions.</li>
        </ul>
        <h3>Cons:</h3>
        <ul>
            <li><strong>Linear Decision Boundary</strong>: Can only learn linear relationships between features and the target.</li>
            <li><strong>Feature Engineering Required</strong>: Requires careful feature engineering (like our word frequency approach) to work well with text data.</li>
            <li><strong>May Underfit</strong>: For complex patterns, it might not capture all the nuances in the data.</li>
            <li><strong>Feature Scaling</strong>: Sensitive to the scale of input features, though less critical with our binary features.</li>
        </ul>
    </div>
</body>
</html>